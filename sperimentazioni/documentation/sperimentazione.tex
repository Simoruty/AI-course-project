\section{Sperimentazione}

\subsection{I file eseguibili}
Per ogni fold di ogni dataset, abbiamo creato in maniera automatica uno script \verb+.yap+ che, se eseguito, si occupa di avviare ALEPH, leggere i file di input, generare le regole e scriverle su file.

Il sorgente dello script (esempio tratto dal fold 0 del dataset elsevier) è il seguente:

\begin{prologcode}
#!/usr/local/bin/yap -L --
#
# .
:- consult('../aleph.pl').
:- read_all('elsevier_f0').
:- induce.
:- write_rules('elsevier_f0.rul').
\end{prologcode}

Tutti i $40$ ($4$ dataset $\times$ $10$ fold) script \verb+.yap+ sono avviati in successione da un unico file scritto in linguaggio \emph{Python}.

Esso si occupa anche di tenere traccia dei tempi di esecuzione per un confronto sulle performance dei sistemi confrontati e di scrivere l'output delle esecuzioni in file \verb+.out+.

Il codice dello script è qui riportato:

\begin{pythoncode}
#!/usr/bin/python

import sys
import os
import subprocess
from time import gmtime, strftime, localtime
from datetime import datetime

cmd = "chmod +x **/*.yap"
subprocess.call(cmd, shell=True)
if not os.path.exists("./result/"):
    os.makedirs("./result/")
for dataset in ["elsevier", "jmlr", "mlj", "svln"]:
    print dataset +" started at "+ strftime("%H:%M:%S", localtime())
    sys.stdout.flush()
    startDataset = datetime.now()
    for fold in range(10):
        startTime = datetime.now()
        print "Fold " + str(fold) +" started at "
        print strftime("%H:%M:%S", localtime())
        sys.stdout.flush()
        cmd = "./"+dataset+"/"+dataset+"_f"+str(fold)
        cmd += ".yap -s50000 -h200000 2>&1 > /dev/null"
        subprocess.call(cmd, shell=True)
        fin = open("./result/"+dataset+".summary","a")
        fin.write("\nFold "+str(fold)+"\n")
        fin.close()
        cmd0 = "cat ./"+dataset+"/"+dataset+"_f"+str(fold)
        cmd0 += ".rul >> ./result/"+dataset+".summary"
        subprocess.call(cmd0, shell=True)
        cmd1 = "cat ./"+dataset+"/"+dataset+"_f"+str(fold)
        cmd1 += ".log | grep -B 10 -m 1 '\[Test set summary\]'"
        cmd1 += " >> ./result/"+dataset+".summary"
        subprocess.call(cmd1, shell=True)
        print "Fold " + str(fold) +" ended in: "
        print str(datetime.now()-startTime)
        sys.stdout.flush()
    print dataset+" ended in "+str(datetime.now()-startDataset)
    sys.stdout.flush()
\end{pythoncode}


\subsection{Hardware utilizzato}
\label{hw}
L'hardware utilizzato ai fini della sperimentazione è stato un notebook Acer Aspire v3-571g aventi le seguenti caratteristiche:
\begin{itemize}
	\item \textbf{Processore}: Intel\textregistered Core\texttrademark  i7-3610QM processor (2.3GHz/3.3GHz w/ Turbo Boost)
	\item \textbf{RAM}: 8GB DDR3 1333 MHz
	\item \textbf{Memoria di archiviazione}: 120GB SSD
	\item \textbf{OS}: elementaryOS 0.2 (luna) basato su Ubuntu 12.04.5 LTS (Precise Pangolin)
\end{itemize}

\subsection{Metriche}
\label{metriche}
In seguito all'esecuzione della sperimentazione, si otterranno di file di output differenti tra i vari algoritmi, ma in tutti, tra le varie informazioni presenti, ci sarà anche la matrice di confusione relativi a come sono stati classificati gli esempi di test.

La matrice di confusione sarà composta quindi da:
\begin{table}[htbp]
\centering
\begin{tabular}{c c c c }
	& & \multicolumn{2}{ c }{Reali} \\
	& & + & - \\
	\multirow{2}{*}{Predetti} & + & TP & FP \\
	& - & FN & TN \\
\end{tabular}
\end{table}


Partendo da queste matrici di confusione ottenute, sono state calcolate delle metriche al fine di verificare quale algoritmo risulti essere più efficiente in termini di classificazione.
Le metriche calcolate sono state:
\begin{itemize}
	\item Precision
	\item Recall
	\item F-Measure
	\item Accuracy
	\item Error
\end{itemize}
Dove la Precision e la recall saranno calcolate rispettivamente dalle formule:
	$$Precision = \frac{TP}{TP + FP}$$
	$$Recall = \frac{TP}{TP + FN}$$
Per quanto riguarda la F-measure invece, è stata calcolata mettendo in relazione entrambe le metriche precedenti tramite la relazione:
$$F = 2*\frac{Precision * Recall}{Precision + Recall}$$
L'accuratezza invece è stata calcolata tramite la formula:
$$Acc = \frac{TP+TN}{TP + TN + FP + FN}$$
Infine è stata calcolato anche l'errore in base all'accuratezza della classificazione:
$$Err = 1 - Acc$$