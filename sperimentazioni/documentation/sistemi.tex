\section{Sistemi di apprendimento}

I sistemi di apprendimento presi in esame saranno di tre tipi differenti:

\begin{itemize}
	\item ALEPH (A Learning Engine for Proposing Hypothesis)
	\item Progol 
	\item FOIL (First Order Inductive Learner)
\end{itemize}

\subsection{ALEPH}
Aleph, acronimo di "\emph{\textbf{A} \textbf{L}earning \textbf{E}ngine for \textbf{P}roposing \textbf{H}ypotheses}", è un sistema di apprendimento ILP (Inductive Logic Programming), il cui scopo principale è quello di  definire il concetto di implicazione inversa.
A differenza di FOIL, questo sistema si basa su una strategia ibrida atta sia generalizzare che specializzare le clausole di Horn. 
Approccio
Randomly pick a positive example, p.
Define the space of possible clauses that could entail that example.
Generate the bottom clause, 
contains all the literals defined in BK that could cover p.
Search this space.

Si mostra di seguito il funzionamento dell’algoritmo base di Aleph:
Per ogni esempio da generalizzare;
Scegli un esempio;
Costruisci la clausola più specifica (bottom clause);
Trova una clausola più generale della bottom clause costruendo
sottoinsiemi di letterali della bottom clause che hanno il
miglior punteggio (Punteggio calcolato da Aleph);
Aggiungi la clausola con il miglior punteggio alla teoria e
rimuovi gli esempi ridondanti;
Ripeti;

ALEPH inoltre possiede una gestione del Test Set leggermente diversa rispetto a FOIL. Infatti una volta avviato il sistema e caricata la background knowledge ALEPH costruisce la sua teoria sugli esempi di training e successivamente gli si forniscono i documenti di test per valutare i risultati dell’apprendimento. Su FOIL invece questo non è possibile, il sistema viene avviato dandogli in input sia il test set che il training set e fornisce direttamente i risultati. Maggiori dettagli sono approfonditi nel capitolo successivo relativo alla fase di riscrittura dei dataset e nel capitolo relativo alla conduzione dell’esperimento vero e proprio.

During routine use, Aleph follows a very simple procedure that can be described in 4 steps:

Select example. Select an example to be generalised. If none exist, stop, otherwise proceed to the next step.
Build most-specific-clause. Construct the most specific clause that entails the example selected, and is within language restrictions provided. This is usually a definite clause with many literals, and is called the "bottom clause." This step is sometimes called the "saturation" step. Details of constructing the bottom clause can be found in Stephen Muggleton's 1995 paper: Inverse Entailment and Progol, New Gen. Comput., 13:245-286, available at ftp://ftp.cs.york.ac.uk/pub/ML_GROUP/Papers/InvEnt.ps.gz.
Search. Find a clause more general than the bottom clause. This is done by searching for some subset of the literals in the bottom clause that has the "best" score. Two points should be noted. First, confining the search to subsets of the bottom clause does not produce all the clauses more general than it, but is good enough for this thumbnail sketch. Second, the exact nature of the score of a clause is not really important here. This step is sometimes called the "reduction" step.
Remove redundant. The clause with the best score is added to the current theory, and all examples made redundant are removed. This step is sometimes called the "cover removal" step. Note here that the best clause may make clauses other than the examples redundant. Again, this is ignored here. Return to Step 1.
A more advanced use of Aleph (see section Advanced use of Aleph) allows alteration to each of these steps. At the core of Aleph is the "reduction" step, presented above as a simple "subset-selection" algorithm. In fact, within Aleph, this is implemented by a (restricted) branch-and-bound algorithm which allows an intelligent enumeration of acceptable clauses under a range of different conditions. More on this can be found in section On how the single-clause search is implemented.



Aleph requires three files to construct theories. They are “filestem.b, filestem.f, and filestem.n,” which stand for background knowledge file, positive example file, and negative example file, respectively. Aleph receives these three files in order to construct a theory that is consistent with positive examples and inconsistent with negative ones.
The background knowledge inputted into Aleph is generated by means of Case-Based Reasoning (CBR) with user interaction if necessary. Sophisticated background knowledge should be provided to efficiently process natural language documents since they are rich in representation. The acquisition of background knowledge is one of the problems to be overcome. On the other hand, the acquisition and compilation of background knowledge have been reported to cause a bottleneck in knowledge engineering because they are very time-consuming tasks. The automatic generation of background knowledge provides a solution to the problem.

\subsection{Progol}

PROGOL è interessante per diversi motivi. primo, ha adottato l'idea dell'algoritmo AQ della ILP. Come AQ, seleziona un esempio come seed e computa una generalizzazione minimale dell'esempio in base alla base di conoscenza disponibile e data una profondità massima di inferenza. la bottom rule risultante è il modo più similare 


Progol is an implementation of Inductive Logic Programming used in computer science that combines "Inverse Entailment" with "general-to-specific search" through a refinement graph. [1][2][3] "Inverse Entailment" is used with mode declarations to derive the most-specific clause within the mode language which entails a given example. This clause is used to guide a refinement-graph search.

Unlike the searches of Ehud Shapiro's Model Inference System (MIS) and J. Ross Quinlan's FOIL Progol's search is efficient and has a provable guarantee of returning a solution having the maximum "compression" in the search-space. To do so it performs an admissible A*-like search, guided by compression, over clauses which subsume the most specific clause.

Progol deals with noisy data by using the "compression measure" to trade-off the description of errors against the hypothesis description length. Progol allows arbitrary Prolog programs as background knowledge and arbitrary definite clauses as examples. Despite this bench-tests show that the efficiency of Progol compares favourably with FOIL.
\nocite{wiki:progol}
%WIKIPEDIA 

P-Progol is intended to be a prototype for exploring ideas. It commenced in 1993 as part of a fun project undertaken by Ashwin Srinivasan and Rui Camacho at Oxford University. The main purpose was to understand ideas of inverse entailment which eventually appeared in Steve Muggleton's paper, and was accompanied by (good-natured) bun-fights about the execution speeds of programs being written by Ashwin (who was writing P-Progol) and Rui (who was writing Indlog). The earliest P-Progol implementation dates from April, 1993. There are, currently, at least 3 implementations based on the Progol algorithm: CProgol (by S. Muggleton, written in C which contains its own Prolog interpreter), Indlog (by Rui Camacho, in Prolog requiring the Yap compiler) and P-Progol (by Ashwin Srinivasan, in Prolog largely developed with Yap). The main differences in implementation (other than language) are in the search technique used and degree of user-interaction allowed

The basic P-Progol algorithm
During routine use, P-Progol follows a very simple procedure that can be described in 4 steps:
Select example. Select an example to be generalised. If none exist, stop, otherwise proceed to the next step.
Build most-specific-clause. Construct the most specific clause that entails the example selected, and is within language restrictions provided. This is usually a definite clause with many literals, and is called the "bottom clause." This step is sometimes called the "saturation" step.
Search. Find a clause more general than the bottom clause. This is done by searching for some subset of the literals in the bottom clause that has the "best" score. Two points should be noted. First, confining the search to subsets of the bottom clause does not produce all the clauses more general than it, but is good enough for this thumbnail sketch. Second, the exact nature of the score of a clause is not really important here. This step is sometimes called the "reduction" step.
Remove redundant. The clause with the best score is added to the current theory, and all examples made redundant are removed. This step is sometimes called the "cover removal" step. Note here that the best clause may make clauses other than the examples redundant. Again, this is ignored here. Return to Step 1.
P-Progol is an implementation based around these 4 steps. A more advanced use of P-Progol (see section Advanced use of P-Progol) allows alteration to each of these steps.


\subsection{FOIL}
\nocite{Quinlan:1993:FMR:645323.649599}
FOIL è un sistema di apprendimento in grado di costruire delle clausole di Horn su una relazione target partendo sia dalla relazione stessa che da altre relazioni. Il sistema è in realtà un po' più flessibile in quanto può apprendere diverse relazioni in sequenza, permettendo sia l'utilizzo di letterali negati all'interno delle definizioni (usando la semantica Prolog), sia l'impiego di alcune costanti all'interno delle definizioni prodotte dal sistema stesso.
FOIL si basa sulla tecnica del \textit{separate-and-conquer}; tecnica basata essenzialmente su due fasi, nella fase di \textit{separate} si andrà a creare una regola che sia in grado di coprire il maggior numero di esempi positivi presenti nel training set; successivamente si andrà a continuare in maniera ricorsiva nella creazione di regola fintanto che non ci saranno più esempi positivi da coprire (fase di conquer).
La metrica utilizzata per definire la regola migliore in termini di copertura sarà una metrica basata sulla teoria dell'informazione come ad esempio il valore entropico che la regola avrà sul training.
Inoltre, FOIL si basa anche sul concetto di CWA, nel senso che, qualora non dovesse avere a disposizione degli esempi negativi su cui andare ad indurre le regole da creare, assumerà che qualunque altro caso o esempio al di fuori di quelli presenti nel training sono da considerarsi negativi (ipotesi del mondo chiuso).
\begin{algorithm}
	\begin{algorithmic}
	\REQUIRE Lista di esempi
	\FORALL {esempi $\in$ Training Set}
	\STATE Pos $\Rightarrow$ contiene tutti gli esempi positivi
	\STATE Pred $\Rightarrow$ contiene il predicato da apprendere
	\WHILE{Pos non è vuoto}
	\STATE Neg $\Rightarrow$ contiene tutti gli esempi negativi
	\STATE Impostare \textit{body} a vuoto
	\WHILE {Neg non è vuoto}
	\STATE Scegliere un letterale L
	\STATE Aggiungere L a Body
	\STATE Rimuovere gli esempi negativi che non soddisfano L
	\ENDWHILE
	\STATE Aggiungere il predicato \textit{pred} al \textit{body}
	\STATE Rimuovere da Pos tutti gli esempi che soddisfano body
	\ENDWHILE
	\ENDFOR
	\RETURN regola nella logica del primo ordine
	\end{algorithmic}
\end{algorithm}